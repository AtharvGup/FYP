Dataset: taowu_schaefer100,
Model: GCN

params={'seed': 41, 'epochs': 1000, 'batch_size': 20, 'init_lr': 0.0029821829617720404, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 25, 'min_lr': 1e-06, 'weight_decay': 0.00023183179636346294, 'print_epoch_interval': 5, 'max_time': 12, 'threshold': 0.3, 'edge_ratio': 0.0, 'node_feat_transform': 'pearson'}

net_params={'L': 3, 'hidden_dim': 256, 'out_dim': 128, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.6, 'batch_norm': True, 'self_loop': False, 'edge_feat': True, 'node_num': 100, 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 20, 'in_dim': 100, 'edge_dim': 1, 'n_classes': 2, 'total_param': 203810}

GCNNet(
  (embedding_h): Linear(in_features=100, out_features=256, bias=True)
  (embedding_e): Linear(in_features=1, out_features=256, bias=True)
  (in_feat_dropout): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0-1): 2 x GCNLayer(in_channels=256, out_channels=256, residual=True)
    (2): GCNLayer(in_channels=256, out_channels=128, residual=False)
  )
  (MLP_layer): MLPReadout(
    (FC_layers): ModuleList(
      (0): Linear(in_features=128, out_features=64, bias=True)
      (1): Linear(in_features=64, out_features=32, bias=True)
      (2): Linear(in_features=32, out_features=2, bias=True)
    )
  )
)

Total Parameters: 203810

 edge_num: 3848


    FINAL RESULTS
TEST ACCURACY averaged: 67.5000 with s.d. 25.1247
TRAIN ACCURACY averaged: 100.0000 with s.d. 0.0000
VAL ACCURACY averaged: 62.5000 with s.d. 37.5000


    TRAIN LOSS averaged: 0.0001 with s.d. 0.0001
VAL LOSS averaged: 2.5054 with s.d. 2.4084


    Average Convergence Time (Epochs): 339.7000 with s.d. 45.1709
Total Time Taken: 0.2001 hrs
Average Time Per Epoch: 0.1930 s


All Splits Test Accuracies: [1.0, 0.5, 0.5, 1.0, 0.25, 0.5, 1.0, 0.5, 0.75, 0.75] 
                
All Splits Train Accuracies: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0] 
All Splits Val Accuracies: [1.0, 1.0, 0.25, 1.0, 0.75, 0.0, 0.75, 0.75, 0.75, 0.0] 
All Splits Train Loss: [5.728446012653876e-05, 3.7869129300815985e-05, 0.00012766151849064045, 3.336173904244788e-05, 8.920137042878196e-05, 5.438537118607201e-05, 0.00020724634669022635, 5.9357091231504455e-05, 0.00029487424762919545, 5.581875393545488e-05], 
                
All Splits Val Loss: [0.1822860687971115, 0.0012911399826407433, 4.0340166091918945, 0.0007764013134874403, 2.2271299362182617, 6.455168724060059, 1.1624013185501099, 1.8497370481491089, 2.1950721740722656, 6.946189880371094]